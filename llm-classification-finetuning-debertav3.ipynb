{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a370c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:12.403402Z",
     "iopub.status.busy": "2025-08-25T13:51:12.403112Z",
     "iopub.status.idle": "2025-08-25T13:51:27.689773Z",
     "shell.execute_reply": "2025-08-25T13:51:27.688865Z"
    },
    "papermill": {
     "duration": 15.291791,
     "end_time": "2025-08-25T13:51:27.691163",
     "exception": false,
     "start_time": "2025-08-25T13:51:12.399372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 13:51:13.800310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756129873.965766      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756129874.013986      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756129887.685274      19 gpu_device.cc:2022] Created device /device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "# Configure GPU memory growth (prevents OOM errors)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d259b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:27.697600Z",
     "iopub.status.busy": "2025-08-25T13:51:27.697038Z",
     "iopub.status.idle": "2025-08-25T13:51:28.974672Z",
     "shell.execute_reply": "2025-08-25T13:51:28.973942Z"
    },
    "papermill": {
     "duration": 1.28216,
     "end_time": "2025-08-25T13:51:28.976131",
     "exception": false,
     "start_time": "2025-08-25T13:51:27.693971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"deberta_v3_extra_small_en\"\n",
    "SEQUENCE_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57673a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:28.982269Z",
     "iopub.status.busy": "2025-08-25T13:51:28.981657Z",
     "iopub.status.idle": "2025-08-25T13:51:32.297557Z",
     "shell.execute_reply": "2025-08-25T13:51:32.296781Z"
    },
    "papermill": {
     "duration": 3.319962,
     "end_time": "2025-08-25T13:51:32.298723",
     "exception": false,
     "start_time": "2025-08-25T13:51:28.978761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57477, 9)\n",
      "Test shape: (3, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n",
    "\n",
    "# Quick inspection\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214e2c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:32.304820Z",
     "iopub.status.busy": "2025-08-25T13:51:32.304574Z",
     "iopub.status.idle": "2025-08-25T13:51:32.737960Z",
     "shell.execute_reply": "2025-08-25T13:51:32.737037Z"
    },
    "papermill": {
     "duration": 0.437675,
     "end_time": "2025-08-25T13:51:32.739148",
     "exception": false,
     "start_time": "2025-08-25T13:51:32.301473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Summary:\n",
      "- Missing values: 0\n",
      "- Duplicates: 0\n",
      "- Target distribution:\n",
      "winner_model_a    0.349079\n",
      "winner_model_b    0.341911\n",
      "winner_tie        0.309011\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Basic validation checks\n",
    "def check_data(df, name):\n",
    "    print(f\"\\n{name} Data Summary:\")\n",
    "    print(\"- Missing values:\", df.isna().sum().sum())\n",
    "    print(\"- Duplicates:\", df.duplicated().sum())\n",
    "    print(\"- Target distribution:\")\n",
    "    print(df[['winner_model_a', 'winner_model_b', 'winner_tie']].mean())\n",
    "\n",
    "\n",
    "check_data(train_df, \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6253237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:32.745807Z",
     "iopub.status.busy": "2025-08-25T13:51:32.745556Z",
     "iopub.status.idle": "2025-08-25T13:51:34.131075Z",
     "shell.execute_reply": "2025-08-25T13:51:34.130455Z"
    },
    "papermill": {
     "duration": 1.390391,
     "end_time": "2025-08-25T13:51:34.132476",
     "exception": false,
     "start_time": "2025-08-25T13:51:32.742085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756129893.750013      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = keras_nlp.models.DebertaV3Tokenizer.from_preset(MODEL_NAME)\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Normalize text for DeBERTa\"\"\"\n",
    "        text = str(text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)  # Collapse whitespace\n",
    "        text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)  # Remove non-ASCII\n",
    "        return text.strip()\n",
    "    \n",
    "    def create_input_pairs(self, row):\n",
    "        \"\"\"Format prompt-response pairs\"\"\"\n",
    "        clean_prompt = self.clean_text(row['prompt'])\n",
    "        return [\n",
    "            f\"Prompt: {clean_prompt} {self.tokenizer.sep_token} Response: {self.clean_text(row['response_a'])}\",\n",
    "            f\"Prompt: {clean_prompt} {self.tokenizer.sep_token} Response: {self.clean_text(row['response_b'])}\"\n",
    "        ]\n",
    "\n",
    "# Initialize processor\n",
    "processor = TextPreprocessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ed0428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:34.139131Z",
     "iopub.status.busy": "2025-08-25T13:51:34.138901Z",
     "iopub.status.idle": "2025-08-25T13:51:45.813344Z",
     "shell.execute_reply": "2025-08-25T13:51:45.812626Z"
    },
    "papermill": {
     "duration": 11.678878,
     "end_time": "2025-08-25T13:51:45.814413",
     "exception": false,
     "start_time": "2025-08-25T13:51:34.135535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Prompt: [\"Is it morally right to try to have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Prompt: [\"What is the difference between marr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Prompt: [\"explain function calling. how would...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Prompt: [\"How can I create a test set for a v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Prompt: [\"What is the best way to travel from...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  label\n",
       "0  [Prompt: [\"Is it morally right to try to have ...      0\n",
       "1  [Prompt: [\"What is the difference between marr...      1\n",
       "2  [Prompt: [\"explain function calling. how would...      2\n",
       "3  [Prompt: [\"How can I create a test set for a v...      0\n",
       "4  [Prompt: [\"What is the best way to travel from...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "train_df['inputs'] = train_df.apply(processor.create_input_pairs, axis=1)\n",
    "test_df['inputs'] = test_df.apply(processor.create_input_pairs, axis=1)\n",
    "\n",
    "# Create labels (0: model_a wins, 1: model_b wins, 2: tie)\n",
    "train_df['label'] = train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)\n",
    "train_df['label'] = train_df['label'].map({'winner_model_a':0, 'winner_model_b':1, 'winner_tie':2})\n",
    "\n",
    "# Preview processed data\n",
    "train_df[['inputs', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d928965a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:45.821171Z",
     "iopub.status.busy": "2025-08-25T13:51:45.820645Z",
     "iopub.status.idle": "2025-08-25T13:51:54.633580Z",
     "shell.execute_reply": "2025-08-25T13:51:54.632701Z"
    },
    "papermill": {
     "duration": 8.817791,
     "end_time": "2025-08-25T13:51:54.635088",
     "exception": false,
     "start_time": "2025-08-25T13:51:45.817297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train/validation split\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.1, \n",
    "    stratify=train_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create TensorFlow datasets with proper input pair handling\n",
    "def create_dataset(text_pairs, labels=None, preprocessor=None):\n",
    "    \"\"\"Convert to optimized TF Dataset with proper input pair handling\"\"\"\n",
    "    AUTO = tf.data.AUTOTUNE\n",
    "    \n",
    "    # Convert to TensorFlow Dataset\n",
    "    if labels is not None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((text_pairs, labels))\n",
    "        ds = ds.shuffle(1000)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(text_pairs)\n",
    "\n",
    "# Preprocessing function\n",
    "    def preprocess_pair(text_pair, label=None):\n",
    "        \"\"\"Convert raw text pairs to model-ready format\"\"\"\n",
    "        # Tokenize each response separately\n",
    "        processed_a = preprocessor(text_pair[0])  # {'token_ids': ..., 'padding_mask': ...}\n",
    "        processed_b = preprocessor(text_pair[1])\n",
    "        \n",
    "        # Stack to create (2, seq_len) tensors\n",
    "        model_inputs = {\n",
    "            \"token_ids\": tf.stack([processed_a[\"token_ids\"], processed_b[\"token_ids\"]], axis=0),\n",
    "            \"padding_mask\": tf.stack([processed_a[\"padding_mask\"], processed_b[\"padding_mask\"]], axis=0)\n",
    "        }\n",
    "        return (model_inputs, label) if label is not None else model_inputs\n",
    "    \n",
    "    # Apply preprocessing and batching\n",
    "    ds = ds.map(preprocess_pair, num_parallel_calls=AUTO)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    MODEL_NAME,\n",
    "    sequence_length=SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "# Prepare all datasets\n",
    "train_ds = create_dataset(\n",
    "    train_df['inputs'].tolist(), \n",
    "    tf.keras.utils.to_categorical(train_df['label']),\n",
    "    preprocessor=preprocessor\n",
    ")\n",
    "valid_ds = create_dataset(\n",
    "    valid_df['inputs'].tolist(), \n",
    "    tf.keras.utils.to_categorical(valid_df['label']),\n",
    "    preprocessor=preprocessor\n",
    ")\n",
    "test_ds = create_dataset(\n",
    "    test_df['inputs'].tolist(),\n",
    "    preprocessor=preprocessor\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5814c59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:54.642337Z",
     "iopub.status.busy": "2025-08-25T13:51:54.641708Z",
     "iopub.status.idle": "2025-08-25T13:51:55.043831Z",
     "shell.execute_reply": "2025-08-25T13:51:55.042838Z"
    },
    "papermill": {
     "duration": 0.406986,
     "end_time": "2025-08-25T13:51:55.045149",
     "exception": false,
     "start_time": "2025-08-25T13:51:54.638163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs shape: (16, 2, 128)\n",
      "Mask shape: (16, 2, 128)\n",
      "Example token_ids[0,0,:5]: tf.Tensor([    1 31751   294   647   309], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Check a batch from your dataset\n",
    "for batch in train_ds.take(1):\n",
    "    inputs, labels = batch\n",
    "    print(\"Token IDs shape:\", inputs[\"token_ids\"].shape)  # Should be (batch_size, 2, 128)\n",
    "    print(\"Mask shape:\", inputs[\"padding_mask\"].shape)\n",
    "    print(\"Example token_ids[0,0,:5]:\", inputs[\"token_ids\"][0,0,:5])  # First 5 tokens of response_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d61ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:51:55.052521Z",
     "iopub.status.busy": "2025-08-25T13:51:55.052283Z",
     "iopub.status.idle": "2025-08-25T13:52:00.897381Z",
     "shell.execute_reply": "2025-08-25T13:52:00.896802Z"
    },
    "papermill": {
     "duration": 5.850168,
     "end_time": "2025-08-25T13:52:00.898720",
     "exception": false,
     "start_time": "2025-08-25T13:51:55.048552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_deberta_classifier():\n",
    "    with tf.device('/GPU:0'):\n",
    "        # Define input layers\n",
    "        token_ids = tf.keras.layers.Input(\n",
    "            shape=(2, SEQUENCE_LENGTH), \n",
    "            dtype=tf.int32,\n",
    "            name=\"token_ids\"\n",
    "        )\n",
    "        padding_mask = tf.keras.layers.Input(\n",
    "            shape=(2, SEQUENCE_LENGTH),\n",
    "            dtype=tf.int32,\n",
    "            name=\"padding_mask\"\n",
    "        )\n",
    "        \n",
    "        inputs = {\"token_ids\": token_ids, \"padding_mask\": padding_mask}\n",
    "\n",
    "# Initialize backbone\n",
    "        backbone = keras_nlp.models.DebertaV3Backbone.from_preset(MODEL_NAME)\n",
    "        \n",
    "        # Process both responses\n",
    "        def process_response(inputs, index):\n",
    "            return {\n",
    "                \"token_ids\": inputs[\"token_ids\"][:, index, :],\n",
    "                \"padding_mask\": inputs[\"padding_mask\"][:, index, :]\n",
    "            }\n",
    "        \n",
    "        emb_a = backbone(process_response(inputs, 0))\n",
    "        emb_b = backbone(process_response(inputs, 1))\n",
    "        \n",
    "        # Classification head\n",
    "        combined = tf.keras.layers.Concatenate()([emb_a, emb_b])\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(combined)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# 2. Build and compile the model\n",
    "model = build_deberta_classifier()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE, weight_decay=0.01),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\", \"categorical_crossentropy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b17a6bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T13:52:00.905191Z",
     "iopub.status.busy": "2025-08-25T13:52:00.904981Z",
     "iopub.status.idle": "2025-08-25T14:13:42.676440Z",
     "shell.execute_reply": "2025-08-25T14:13:42.675800Z"
    },
    "papermill": {
     "duration": 1301.77644,
     "end_time": "2025-08-25T14:13:42.678161",
     "exception": false,
     "start_time": "2025-08-25T13:52:00.901721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756130023.194777      57 service.cc:148] XLA service 0x7e296c0037d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756130023.195570      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1756130033.640128      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1756130106.936922      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3234/3234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1301s\u001b[0m 345ms/step - accuracy: 0.3518 - categorical_crossentropy: 1.2200 - loss: 1.2233 - val_accuracy: 0.4226 - val_categorical_crossentropy: 1.0755 - val_loss: 1.0820 - learning_rate: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_model.weights.h5\", save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd23263f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T14:13:42.950827Z",
     "iopub.status.busy": "2025-08-25T14:13:42.950550Z",
     "iopub.status.idle": "2025-08-25T14:13:54.960858Z",
     "shell.execute_reply": "2025-08-25T14:13:54.960081Z"
    },
    "papermill": {
     "duration": 12.147446,
     "end_time": "2025-08-25T14:13:54.962076",
     "exception": false,
     "start_time": "2025-08-25T14:13:42.814630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "Submission saved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.284711</td>\n",
       "      <td>0.245067</td>\n",
       "      <td>0.470222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.365644</td>\n",
       "      <td>0.391665</td>\n",
       "      <td>0.242691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.286851</td>\n",
       "      <td>0.375885</td>\n",
       "      <td>0.337264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.284711        0.245067    0.470222\n",
       "1   211333        0.365644        0.391665    0.242691\n",
       "2  1233961        0.286851        0.375885    0.337264"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "test_preds = model.predict(test_ds)\n",
    "test_df['prediction'] = np.argmax(test_preds, axis=1)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "            \"id\": test_df.id,\n",
    "            \"winner_model_a\": test_preds[:, 0],\n",
    "            \"winner_model_b\": test_preds[:, 1],\n",
    "            \"winner_tie\": test_preds[:, 2]\n",
    "        })\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission saved!\")\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1370.747166,
   "end_time": "2025-08-25T14:13:59.177540",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-25T13:51:08.430374",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
