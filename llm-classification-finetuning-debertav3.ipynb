{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":86518,"databundleVersionId":9809560},{"sourceType":"modelInstanceVersion","sourceId":6063,"databundleVersionId":7429216,"modelInstanceId":4684}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\nprint(tf.test.gpu_device_name())\n\n# Configure GPU memory growth (prevents OOM errors)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:21.358139Z","iopub.execute_input":"2025-08-25T10:57:21.358779Z","iopub.status.idle":"2025-08-25T10:57:35.278171Z","shell.execute_reply.started":"2025-08-25T10:57:21.358743Z","shell.execute_reply":"2025-08-25T10:57:35.277499Z"}},"outputs":[{"name":"stderr","text":"2025-08-25 10:57:22.795918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756119442.978469      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756119443.033865      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Num GPUs Available:  2\n/device:GPU:0\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1756119455.273188      36 gpu_device.cc:2022] Created device /device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756119455.273846      36 gpu_device.cc:2022] Created device /device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras_nlp\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\n\n# Configuration\nMODEL_NAME = \"deberta_v3_extra_small_en\"\nSEQUENCE_LENGTH = 128\nBATCH_SIZE = 16\nEPOCHS = 1\nLEARNING_RATE = 5e-6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:35.279474Z","iopub.execute_input":"2025-08-25T10:57:35.280350Z","iopub.status.idle":"2025-08-25T10:57:36.543494Z","shell.execute_reply.started":"2025-08-25T10:57:35.280313Z","shell.execute_reply":"2025-08-25T10:57:36.542945Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n\n# Quick inspection\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape:\", test_df.shape)\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:36.544298Z","iopub.execute_input":"2025-08-25T10:57:36.544575Z","iopub.status.idle":"2025-08-25T10:57:39.868929Z","shell.execute_reply.started":"2025-08-25T10:57:36.544545Z","shell.execute_reply":"2025-08-25T10:57:39.868330Z"}},"outputs":[{"name":"stdout","text":"Train shape: (57477, 9)\nTest shape: (3, 4)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Basic validation checks\ndef check_data(df, name):\n    print(f\"\\n{name} Data Summary:\")\n    print(\"- Missing values:\", df.isna().sum().sum())\n    print(\"- Duplicates:\", df.duplicated().sum())\n    print(\"- Target distribution:\")\n    print(df[['winner_model_a', 'winner_model_b', 'winner_tie']].mean())\n\n\ncheck_data(train_df, \"Train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:39.870322Z","iopub.execute_input":"2025-08-25T10:57:39.870533Z","iopub.status.idle":"2025-08-25T10:57:40.308683Z","shell.execute_reply.started":"2025-08-25T10:57:39.870516Z","shell.execute_reply":"2025-08-25T10:57:40.308000Z"}},"outputs":[{"name":"stdout","text":"\nTrain Data Summary:\n- Missing values: 0\n- Duplicates: 0\n- Target distribution:\nwinner_model_a    0.349079\nwinner_model_b    0.341911\nwinner_tie        0.309011\ndtype: float64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class TextPreprocessor:\n    def __init__(self):\n        self.tokenizer = keras_nlp.models.DebertaV3Tokenizer.from_preset(MODEL_NAME)\n        \n    def clean_text(self, text):\n        \"\"\"Normalize text for DeBERTa\"\"\"\n        text = str(text)\n        text = re.sub(r\"\\s+\", \" \", text)  # Collapse whitespace\n        text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)  # Remove non-ASCII\n        return text.strip()\n    \n    def create_input_pairs(self, row):\n        \"\"\"Format prompt-response pairs\"\"\"\n        clean_prompt = self.clean_text(row['prompt'])\n        return [\n            f\"Prompt: {clean_prompt} {self.tokenizer.sep_token} Response: {self.clean_text(row['response_a'])}\",\n            f\"Prompt: {clean_prompt} {self.tokenizer.sep_token} Response: {self.clean_text(row['response_b'])}\"\n        ]\n\n# Initialize processor\nprocessor = TextPreprocessor()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:40.309390Z","iopub.execute_input":"2025-08-25T10:57:40.309629Z","iopub.status.idle":"2025-08-25T10:57:42.197738Z","shell.execute_reply.started":"2025-08-25T10:57:40.309610Z","shell.execute_reply":"2025-08-25T10:57:42.196959Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1756119461.838743      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1756119461.838950      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Apply preprocessing\ntrain_df['inputs'] = train_df.apply(processor.create_input_pairs, axis=1)\ntest_df['inputs'] = test_df.apply(processor.create_input_pairs, axis=1)\n\n# Create labels (0: model_a wins, 1: model_b wins, 2: tie)\ntrain_df['label'] = train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)\ntrain_df['label'] = train_df['label'].map({'winner_model_a':0, 'winner_model_b':1, 'winner_tie':2})\n\n# Preview processed data\ntrain_df[['inputs', 'label']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:42.198884Z","iopub.execute_input":"2025-08-25T10:57:42.199195Z","iopub.status.idle":"2025-08-25T10:57:54.151668Z","shell.execute_reply.started":"2025-08-25T10:57:42.199169Z","shell.execute_reply":"2025-08-25T10:57:54.151086Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                              inputs  label\n0  [Prompt: [\"Is it morally right to try to have ...      0\n1  [Prompt: [\"What is the difference between marr...      1\n2  [Prompt: [\"explain function calling. how would...      2\n3  [Prompt: [\"How can I create a test set for a v...      0\n4  [Prompt: [\"What is the best way to travel from...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inputs</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Prompt: [\"Is it morally right to try to have ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Prompt: [\"What is the difference between marr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Prompt: [\"explain function calling. how would...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[Prompt: [\"How can I create a test set for a v...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Prompt: [\"What is the best way to travel from...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Train/validation split\ntrain_df, valid_df = train_test_split(\n    train_df, \n    test_size=0.1, \n    stratify=train_df['label'],\n    random_state=42\n)\n\n# Create TensorFlow datasets with proper input pair handling\ndef create_dataset(text_pairs, labels=None, preprocessor=None):\n    \"\"\"Convert to optimized TF Dataset with proper input pair handling\"\"\"\n    AUTO = tf.data.AUTOTUNE\n    \n    # Convert to TensorFlow Dataset\n    if labels is not None:\n        ds = tf.data.Dataset.from_tensor_slices((text_pairs, labels))\n        ds = ds.shuffle(1000)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(text_pairs)\n\n# Preprocessing function\n    def preprocess_pair(text_pair, label=None):\n        \"\"\"Convert raw text pairs to model-ready format\"\"\"\n        # Tokenize each response separately\n        processed_a = preprocessor(text_pair[0])  # {'token_ids': ..., 'padding_mask': ...}\n        processed_b = preprocessor(text_pair[1])\n        \n        # Stack to create (2, seq_len) tensors\n        model_inputs = {\n            \"token_ids\": tf.stack([processed_a[\"token_ids\"], processed_b[\"token_ids\"]], axis=0),\n            \"padding_mask\": tf.stack([processed_a[\"padding_mask\"], processed_b[\"padding_mask\"]], axis=0)\n        }\n        return (model_inputs, label) if label is not None else model_inputs\n    \n    # Apply preprocessing and batching\n    ds = ds.map(preprocess_pair, num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n    return ds\n\n# Initialize preprocessor\npreprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    MODEL_NAME,\n    sequence_length=SEQUENCE_LENGTH\n)\n\n# Prepare all datasets\ntrain_ds = create_dataset(\n    train_df['inputs'].tolist(), \n    tf.keras.utils.to_categorical(train_df['label']),\n    preprocessor=preprocessor\n)\nvalid_ds = create_dataset(\n    valid_df['inputs'].tolist(), \n    tf.keras.utils.to_categorical(valid_df['label']),\n    preprocessor=preprocessor\n)\ntest_ds = create_dataset(\n    test_df['inputs'].tolist(),\n    preprocessor=preprocessor\n)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:57:54.152248Z","iopub.execute_input":"2025-08-25T10:57:54.152431Z","iopub.status.idle":"2025-08-25T10:58:03.526350Z","shell.execute_reply.started":"2025-08-25T10:57:54.152417Z","shell.execute_reply":"2025-08-25T10:58:03.525754Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Check a batch from your dataset\nfor batch in train_ds.take(1):\n    inputs, labels = batch\n    print(\"Token IDs shape:\", inputs[\"token_ids\"].shape)  # Should be (batch_size, 2, 128)\n    print(\"Mask shape:\", inputs[\"padding_mask\"].shape)\n    print(\"Example token_ids[0,0,:5]:\", inputs[\"token_ids\"][0,0,:5])  # First 5 tokens of response_a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:58:03.527183Z","iopub.execute_input":"2025-08-25T10:58:03.527423Z","iopub.status.idle":"2025-08-25T10:58:03.908877Z","shell.execute_reply.started":"2025-08-25T10:58:03.527404Z","shell.execute_reply":"2025-08-25T10:58:03.908282Z"}},"outputs":[{"name":"stdout","text":"Token IDs shape: (16, 2, 128)\nMask shape: (16, 2, 128)\nExample token_ids[0,0,:5]: tf.Tensor([    1 31751   294   647   309], shape=(5,), dtype=int32)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def build_deberta_classifier():\n    with tf.device('/GPU:0'):\n        # Define input layers\n        token_ids = tf.keras.layers.Input(\n            shape=(2, SEQUENCE_LENGTH), \n            dtype=tf.int32,\n            name=\"token_ids\"\n        )\n        padding_mask = tf.keras.layers.Input(\n            shape=(2, SEQUENCE_LENGTH),\n            dtype=tf.int32,\n            name=\"padding_mask\"\n        )\n        \n        inputs = {\"token_ids\": token_ids, \"padding_mask\": padding_mask}\n\n# Initialize backbone\n        backbone = keras_nlp.models.DebertaV3Backbone.from_preset(MODEL_NAME)\n        \n        # Process both responses\n        def process_response(inputs, index):\n            return {\n                \"token_ids\": inputs[\"token_ids\"][:, index, :],\n                \"padding_mask\": inputs[\"padding_mask\"][:, index, :]\n            }\n        \n        emb_a = backbone(process_response(inputs, 0))\n        emb_b = backbone(process_response(inputs, 1))\n        \n        # Classification head\n        combined = tf.keras.layers.Concatenate()([emb_a, emb_b])\n        x = tf.keras.layers.GlobalAveragePooling1D()(combined)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n    \n    return tf.keras.Model(inputs=inputs, outputs=outputs)\n\n# 2. Build and compile the model\nmodel = build_deberta_classifier()\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE, weight_decay=0.01),\n    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n    metrics=[\"accuracy\", \"categorical_crossentropy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:58:03.909695Z","iopub.execute_input":"2025-08-25T10:58:03.909957Z","iopub.status.idle":"2025-08-25T10:58:10.250648Z","shell.execute_reply.started":"2025-08-25T10:58:03.909938Z","shell.execute_reply":"2025-08-25T10:58:10.250099Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Callbacks\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n    tf.keras.callbacks.ModelCheckpoint(\"best_model.weights.h5\", save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1)\n]\n\n# Train model\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    epochs=EPOCHS,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T10:58:10.252225Z","iopub.execute_input":"2025-08-25T10:58:10.252442Z","iopub.status.idle":"2025-08-25T11:33:16.835545Z","shell.execute_reply.started":"2025-08-25T10:58:10.252426Z","shell.execute_reply":"2025-08-25T11:33:16.833858Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1756119596.581457      99 service.cc:148] XLA service 0x7e9048003b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1756119596.585118      99 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1756119596.585138      99 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1756119607.310216      99 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1756119679.823739      99 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3234/3234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.3548 - categorical_crossentropy: 1.2847 - loss: 1.2879","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2319910150.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;31m# Only restart wait if we beat both the baseline and our previous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# best.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;34m\"\"\"Return the values of `layer.weights` as a list of NumPy arrays.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;34m\"\"\"Return the values of `layer.weights` as a list of NumPy arrays.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    713\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"# Generate predictions\ntest_preds = model.predict(test_ds)\ntest_df['prediction'] = np.argmax(test_preds, axis=1)\n\n# Create submission\nsubmission = pd.DataFrame({\n            \"id\": test_df.id,\n            \"winner_model_a\": test_preds[:, 0],\n            \"winner_model_b\": test_preds[:, 1],\n            \"winner_tie\": test_preds[:, 2]\n        })\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission saved!\")\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T11:33:17.237758Z","iopub.execute_input":"2025-08-25T11:33:17.238014Z","iopub.status.idle":"2025-08-25T11:33:31.610897Z","shell.execute_reply.started":"2025-08-25T11:33:17.237994Z","shell.execute_reply":"2025-08-25T11:33:31.610303Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\nSubmission saved!\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.254622        0.293031    0.452347\n1   211333        0.358595        0.322784    0.318621\n2  1233961        0.342069        0.349129    0.308803","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.254622</td>\n      <td>0.293031</td>\n      <td>0.452347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.358595</td>\n      <td>0.322784</td>\n      <td>0.318621</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>0.342069</td>\n      <td>0.349129</td>\n      <td>0.308803</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11}]}